
## What if errors are not normally distributed? (Generalized linear models)

Here are three examples of generalized linear models. The first is analyzed using nominal logistic regression, the second is analyzed via ordinal logistic regression, and the third is analyzed via Poisson regression.

As Wikipedia tells us, a generalized linear model or GLM is a flexible generalization of ordinary linear regression that allows for response variables with error distribution models other than a normal distribution.
There is also something called a *general* linear model but it is not the same thing as a *generalized* linear model. It is just the general form of the ordinary linear regression model: $\mathbfit{Y=X\beta+\epsilon}$.

GLMs that we examine here are good for between-subjects studies so we'll actually recode one of our fictitious data sets to be between subjects just to have an example to use.

### Preferences among websites by males and females (GLM 1: Nominal logistic regression for preference responses)

###  Multinomial distribution with logit link function

The `prefsABCsex.csv` file records preferences among three websites A, B, and C expressed by males and females. The subject number, preference and sex were recorded.

The logit link function is the log odds function, generally $\text{logit}(p)=\ln \frac{p}{1-p}$, where $p$ is the probability of an event such as choosing website A. The form of the link function is $\mathbfit{X\beta}=\ln\frac{\mu}{1-\mu}$. This is just the relationship of a matrix of predictors times a vector of parameters $\mathbfit{\beta}$ to the logit of the mean of the distribution.

```{r out.width='75%'}
prefsABCsex <- read_csv(paste0(Sys.getenv("STATS_DATA_DIR"),"/prefsABCsex.csv"))
head(prefsABCsex)
prefsABCsex$Subject<-factor(prefsABCsex$Subject)
prefsABCsex$Sex<-factor(prefsABCsex$Sex)
summary(prefsABCsex)
ggplot(prefsABCsex[prefsABCsex$Sex == "M",],aes(Pref)) +
  theme_tufte() +
  geom_bar(width=0.25,fill="gray") +
  geom_hline(yintercept=seq(0, 20, 5), col="white", lwd=1) +
  annotate("text", x = 1.5, y = 18, adj=1,  family="serif",
    label = c("Males prefer\nwebsite C"))
ggplot(prefsABCsex[prefsABCsex$Sex == "F",],aes(Pref)) +
  theme_tufte() +
  geom_bar(width=0.25,fill="gray") +
  geom_hline(yintercept=seq(0, 20, 5), col="white", lwd=1) +
  annotate("text", x = 1.5, y = 18, adj=1,  family="serif",
    label = c("Females dislike\nwebsite A"))
```

These histograms lead us to suspect that C is preferred by males and that A is disliked by females, but we should still run tests to be convinced that the variability observed is not due to chance.

Analyze Pref by Sex using multinomial logistic regression, aka nominal logistic regression. Here we are testing for whether there is a difference between the sexes regarding their preferences.

The annotation `type=3` is borrowed from SAS and refers to one of three ways of handling an unbalanced design. This experimental design is unbalanced because there are more males than females being tested. This way of handling the unbalanced design is only valid if there are significant interactions, as hinted by the gross differences between the preceding histograms.

```{r}
library(nnet) # provides multinom()
#. library(car) # provides Anova()
#. set sum-to-zero contrasts for the Anova call
contrasts(prefsABCsex$Sex) <- "contr.sum"
m<-multinom(Pref~Sex, data=prefsABCsex)
Anova(m, type=3)
```

The Analysis of Deviance table tells us that there is a significant main effect for Sex. It does not tell us more detail but motivates pairwise tests to get more detail. If there were no significant effect, pairwise tests would not be warranted.

Pairwise tests tell which of the bins are over or under populated based on the assumption that each bin should contain one third of the observations (hence `p=1/3`). When making multiple comparisons we would overstate the significance of the differences so we use Holm's sequential Bonferroni procedure to correct this.

```{r}
ma<-binom.test(sum(prefsABCsex[prefsABCsex$Sex == "M",]$Pref == "A"),
	       nrow(prefsABCsex[prefsABCsex$Sex == "M",]), p=1/3)
mb<-binom.test(sum(prefsABCsex[prefsABCsex$Sex == "M",]$Pref == "B"),
	       nrow(prefsABCsex[prefsABCsex$Sex == "M",]), p=1/3)
mc<-binom.test(sum(prefsABCsex[prefsABCsex$Sex == "M",]$Pref == "C"),
	       nrow(prefsABCsex[prefsABCsex$Sex == "M",]), p=1/3)
#. correct for multiple comparisons
p.adjust(c(ma$p.value, mb$p.value, mc$p.value), method="holm")

fa<-binom.test(sum(prefsABCsex[prefsABCsex$Sex == "F",]$Pref == "A"),
	       nrow(prefsABCsex[prefsABCsex$Sex == "F",]), p=1/3)
fb<-binom.test(sum(prefsABCsex[prefsABCsex$Sex == "F",]$Pref == "B"),
	       nrow(prefsABCsex[prefsABCsex$Sex == "F",]), p=1/3)
fc<-binom.test(sum(prefsABCsex[prefsABCsex$Sex == "F",]$Pref == "C"),
	       nrow(prefsABCsex[prefsABCsex$Sex == "F",]), p=1/3)
#. correct for multiple comparisons
p.adjust(c(fa$p.value, fb$p.value, fc$p.value), method="holm")
```

The preceding tests confirm what we suspected from looking at histograms: males prefer C and females dislike A. We see this by looking at the adjusted $p$-values, where the first row, third value is significant and the second row, first value is significant.

How would we write this up in a report? We could make the following claim. We tested the main effect for sex and found a significant result, $\chi^2_2=7.1, p<0.05$. An exact binomial test found the preference among males for website C greater than chance, $p<0.01$. An exact binomial test found the preference among females against website A greater than chance, $p<0.05$. No other significant differences were found.

### Judgments of perceived effort (GLM 2: Ordinal logistic regression for Likert responses)

### Multinomial distribution with cumulative logit link function
In this example, users are either searching, scrolling or using voice to find contacts in a smartphone address book. The time it takes to find a certain number of contacts, the perceived effort, and the number of errors are all recorded. Of interest now is the perceived effort, recorded on a Likert scale. A Likert scale can not be normally distributed because of the restrictions on the ends and is not likely to even look vaguely normal.

The cumulative logit link function is like the logit link function:

$$\text{logit}(P(Y\leqslant j|x))=\ln\frac{P(Y\leqslant j|x)}{1-P(Y\leqslant j|x)} \text{ where }Y=1,2,\ldots,J$$

In this case $J$ ranges from 1 to 7.

Read in the data and examine it. We see that it is a within-subjects study but it is a fictitious study anyway so we will recode it as if it were a between-subjects study. Then we will be able to apply the following techniques, which we would have to modify for a within-subjects study.

```{r}
srchscrlvce <- read_csv(paste0(Sys.getenv("STATS_DATA_DIR"),"/srchscrlvce.csv"))
head(srchscrlvce)
srchscrlvce$Subject<-(1:nrow(srchscrlvce)) # recode as between-subjects
srchscrlvce$Subject<-factor(srchscrlvce$Subject)
srchscrlvce$Technique<-factor(srchscrlvce$Technique)
srchscrlvce$Order<-NULL # drop order, n/a for between-subjects
head(srchscrlvce) # verify
summary(srchscrlvce)
```

A good description of Effort is the median and quantiles. Another good description is the mean and standard deviation.

```{r out.width="75%"}
plyr::ddply(srchscrlvce, ~ Technique,
       function(data) summary(data$Effort))
plyr::ddply(srchscrlvce, ~ Technique,
       summarize, Effort.mean=mean(Effort), Effort.sd=sd(Effort))
par(cex=0.6)
ggplot(srchscrlvce,aes(Effort,fill=Technique)) +
  geom_histogram(bins=7,alpha=0.8,position="dodge") +
  scale_color_grey() +
  scale_fill_grey() +
  theme_tufte()
ggplot(srchscrlvce,aes(Technique,Effort,fill=Technique)) +
  geom_tufteboxplot(show.legend=FALSE) +
  theme_tufte()
```

The boxplots (these are Tufte-style boxplots) are not encouraging. We may not find a significant difference among these three techniques but let us try anyway.
We analyze Effort Likert ratings by Technique using ordinal logistic regression.

```{r}
#. library(MASS) # provides polr()
#. library(car) # provides Anova()
srchscrlvce$Effort <- ordered(srchscrlvce$Effort)
#. set sum-to-zero contrasts for the Anova call
contrasts(srchscrlvce$Technique) <- "contr.sum"
m <- polr(Effort ~ Technique, data=srchscrlvce, Hess=TRUE) # ordinal logistic
Anova(m, type=3)
```

Post hoc pairwise comparisons are NOT justified due to lack of significance
but here's how we would do them, just for completeness.
`Tukey` means to compare all pairs and `holm` is the adjustment due to the double-counting that overstates the significance.

```{r}
summary(glht(m, mcp(Technique="Tukey")), test=adjusted(type="holm"))
```

How would we express this in a report? We would simply say that we found no significant differences between the three techniques.

### Counting errors in a task (GLM 3: Poisson regression for count responses)

### Poisson distribution with log link function

Using the same data but now focus on the Errors column instead of effort. Errors likely have a Poisson distribution. The log link function is just $\mathbfit{X\beta}=\ln(\mu)$ rather than the more elaborate logit link function we saw before.

```{r}
plyr::ddply(srchscrlvce, ~ Technique,
             function(data) summary(data$Errors))
plyr::ddply(srchscrlvce, ~ Technique, summarize,
             Errors.mean=mean(Errors), Errors.sd=sd(Errors))
par(cex=0.6)
ggplot(srchscrlvce,aes(Errors,fill=Technique)) +
  geom_histogram(bins=9,alpha=0.8,position="dodge") +
  scale_color_grey() +
  scale_fill_grey() +
  theme_tufte()
ggplot(srchscrlvce,aes(Technique,Errors,fill=Technique)) +
  geom_boxplot(show.legend=FALSE) +
  scale_fill_brewer(palette="Greens") +
  theme_tufte()
```

These boxplots are very encouraging. There appears to be a clear difference between all three of these techniques. Notice that you could draw horizontal lines across the plot without intersecting the boxes. That represents a high degree of separation.

Now verify that these data are Poisson-distributed with a goodness-of-fit test for each technique. If the results are *not* significant, we expect that the data do not deviate significantly from what we would expect of a Poisson distribution.

```{r}
#. library(fitdistrplus)
fit<-fitdist(srchscrlvce[srchscrlvce$Technique == "Search",]$Errors,
              "pois", discrete=TRUE)
gofstat(fit)
fit<-fitdist(srchscrlvce[srchscrlvce$Technique == "Scroll",]$Errors,
              "pois", discrete=TRUE)
gofstat(fit)
fit<-fitdist(srchscrlvce[srchscrlvce$Technique == "Voice",]$Errors,
              "pois", discrete=TRUE)
gofstat(fit)
```

All three of the above goodness of fit tests tell us that there is no evidence of deviation from a Poisson distribution. Since we are now convinced of the Poisson distribution for each of the three techniques, analyze the errors using Poisson regression.

We've been saying "set sum-to-zero contrasts for the Anova call" but what does that mean? Contrasts are linear combinations used in ANOVA. As Wikipedia defines it, a contrast is a linear combination $\sum^t_{i=1}a_i\theta_i$, where each $\theta_i$ is a statistic and the $a_i$ values sum to zero. Typically, the $a_i$ values are $1$ and $-1$. A simple contrast represents a difference between means and is used in ANOVA. In R, they are invisible if you use Type I ANOVA, but have to be specified as follows if using a Type III ANOVA. The default `anova()` function is Type I but we're using Type III, available from the `Anova()` function in the `car` package.

A minor detail is that we don't really need to use `Anova()` here instead of `anova()` because the study is balanced, meaning that it has the same number of observations in each condition. The only reason for using `Anova()` on this data is that it gives a better-looking output. The `anova()` function would just display the $\chi^2$ statistic without the associated $p$-value.

```{r out.width="75%"}
contrasts(srchscrlvce$Technique) <- "contr.sum"
#. family parameter identifies both distribution and link fn
m <- glm(Errors ~ Technique, data=srchscrlvce, family=poisson)
Anova(m, type=3)
```

Because the Analysis of Deviance table shows a significant $\chi^2$ value and corresponding $p$-value, we are justified to
conduct pairwise comparisons among levels of Technique.

```{r}
#. library(multcomp)
summary(glht(m, mcp(Technique="Tukey")), test=adjusted(type="holm"))
```

We see from the table that all three differences are significant. We could have guessed this result from glancing at the boxplot above, but it is valuable to have statistical evidence that this is not a chance difference.

